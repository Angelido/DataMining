{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to perform a **predictive analysis** in order to classify our customers in three categories (high-spending, low-spending and medium-spending) on the basis of their shopping behaviour.\n",
    "\n",
    "We will run, compare and discuss the performance of **10 different models**:\n",
    "\n",
    "**Neighbors-based classifiers**\n",
    "- K-Nearest Neighbors\n",
    "- Radius-Neighbors\n",
    "\n",
    "**Naive Bayes classifiers**\n",
    "- Gaussian Naive Bayes\n",
    "- Multinomial Naive Bayes\n",
    "\n",
    "**Support Vector Machine**\n",
    "- Support Vector Classification\n",
    "\n",
    "**Machine Learning classifiers**\n",
    "- Feed-forward Neural Network\n",
    "- Multi-layer Perceptron\n",
    "\n",
    "**Tree-based classifiers**\n",
    "- Decision tree\n",
    "\n",
    "**Ensemble Method**\n",
    "- Random forest\n",
    "- Voting classifier\n",
    "\n",
    "At the end of this notebook, we propose an alternative classification having the label based on the clustering result of with DBSCAN.\n",
    "In fact, given that this algorithm had already identified clusters of clients grouped according to their shopping behavior, we believe that it may be interesting to present this second analysis (in addition to the first one based on the Savg attribute) and show a comparison between the two approaches.\n",
    "This second analysis will be performed on all the ten proposed classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_num = pd.read_csv('dataset/incidents_num.csv')\n",
    "incidents_cat = pd.read_csv('dataset/incidents_cat.csv')\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import copy\n",
    "\n",
    "# dataset_without_string = copy.copy(join_dataset)\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# columns_not_numeric = [ 'state', 'city_or_county', 'address', 'incident_characteristics1', 'party']\n",
    "# for column in columns_not_numeric:\n",
    "#     dataset_without_string[column] = le.fit_transform(dataset_without_string[column])\n",
    "\n",
    "# dataset_without_string.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
